{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a562278",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '../data/raw/training_set_VU_DM.csv'\n",
    "list_of_chunks = []\n",
    "for chunk in pd.read_csv(train_data_path, chunksize=100000):\n",
    "    chunk[\"search_month\"] = pd.to_datetime(chunk[\"date_time\"]).dt.month\n",
    "    modified_chunk = chunk.drop(columns=[\"date_time\",\"gross_bookings_usd\"])\n",
    "    list_of_chunks.append(modified_chunk)\n",
    "df = pd.concat(list_of_chunks, ignore_index=True)\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adb5433",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Comprehensive Data Overview ---\")\n",
    "\n",
    "summary_list = []\n",
    "\n",
    "for col in df.columns:\n",
    "    col_summary = {\n",
    "        'Feature': col,\n",
    "        'Data Type': df[col].dtype,\n",
    "        'Non-Null Count': df[col].count(),\n",
    "        'Missing Count': df[col].isnull().sum(),\n",
    "        'Missing (%)': f\"{df[col].isnull().mean() * 100:.2f}%\",\n",
    "        'Unique Values': df[col].nunique()\n",
    "    }\n",
    "    \n",
    "    if pd.api.types.is_numeric_dtype(df[col]):\n",
    "        col_summary['Mean'] = f\"{df[col].mean():.2f}\"\n",
    "        col_summary['Median'] = f\"{df[col].median():.2f}\"\n",
    "        col_summary['Std Dev'] = f\"{df[col].std():.2f}\"\n",
    "        col_summary['Min'] = f\"{df[col].min():.2f}\"\n",
    "        col_summary['25%'] = f\"{df[col].quantile(0.25):.2f}\"\n",
    "        col_summary['75%'] = f\"{df[col].quantile(0.75):.2f}\"\n",
    "        col_summary['Max'] = f\"{df[col].max():.2f}\"\n",
    "    else: # Top Value and Frequency for non numeric  data\n",
    "        col_summary['Top Value'] = df[col].mode()[0] if not df[col].mode().empty else 'N/A'\n",
    "        col_summary['Top Freq'] = df[col].value_counts().iloc[0] if not df[col].value_counts().empty else 'N/A'\n",
    "        \n",
    "    summary_list.append(col_summary)\n",
    "\n",
    "\n",
    "df_summary = pd.DataFrame(summary_list)\n",
    "\n",
    "\n",
    "\n",
    "print(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1fc57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.isna().sum())\n",
    "missing_percentages = df.isna().sum()/len(df)*100\n",
    "missing_percentages_sorted = missing_percentages[missing_percentages > 0].sort_values(ascending=False)\n",
    "print(missing_percentages_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f8723",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not missing_percentages_sorted.empty:\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        missing_percentages_sorted.plot(kind='barh', color='purple')\n",
    "        plt.title('Percentage of Missing Values per Column (in df_processed)')\n",
    "        plt.ylabel('Percentage Missing (%)')\n",
    "        plt.xticks(rotation=75, ha='right')\n",
    "        plt.tight_layout() \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81960e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location_scores = df.loc[:,['prop_location_score1', 'prop_location_score2']]\n",
    "# print(location_scores)\n",
    "print(df['orig_destination_distance'].sample(50))\n",
    "plt.figure(figsize=(15, 7))\n",
    "# sns.histplot(df['orig_destination_distance'], bins=100, kde=True)\n",
    "sns.boxplot(x=df['orig_destination_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c877dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Distribution of click_bool ---\")\n",
    "plt.figure(figsize=(3, 6))\n",
    "sns.countplot(x='click_bool',hue='click_bool', data=df, palette=\"pastel\",legend=False)\n",
    "plt.title('Distribution of click_bool')\n",
    "plt.xlabel('Clicked (0=No, 1=Yes)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "total_clicks = len(df['click_bool'])\n",
    "if total_clicks > 0: \n",
    "    for p in plt.gca().patches:\n",
    "        percentage = f'{100 * p.get_height() / total_clicks:.1f}%'\n",
    "        x_ann = p.get_x() + p.get_width() / 2\n",
    "        y_ann = p.get_height()\n",
    "        plt.gca().annotate(percentage, (x_ann, y_ann), ha='center', va='bottom')\n",
    "plt.show()\n",
    "print(df['click_bool'].value_counts(normalize=True))\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5006791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Distribution of booking_bool ---\")\n",
    "plt.figure(figsize=(3, 6))\n",
    "sns.countplot(x='booking_bool',hue='booking_bool', data=df, palette=\"pastel\",legend=False)\n",
    "plt.title('Distribution of booking_bool')\n",
    "plt.xlabel('Booked (0=No, 1=Yes)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "total_bookings = len(df['booking_bool'])\n",
    "if total_bookings > 0: \n",
    "    for p in plt.gca().patches:\n",
    "        percentage = f'{100 * p.get_height() / total_bookings:.1f}%'\n",
    "        x_ann = p.get_x() + p.get_width() / 2\n",
    "        y_ann = p.get_height()\n",
    "        plt.gca().annotate(percentage, (x_ann, y_ann), ha='center', va='bottom')\n",
    "plt.show()\n",
    "print(df['booking_bool'].value_counts(normalize=True))\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3847dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing values\n",
    "#prop_review_score\n",
    "print(\"Review scores filling\")\n",
    "mean_review_value = df['prop_review_score'].mean()\n",
    "print(df['prop_review_score'].isna().sum())\n",
    "df['prop_review_score'].fillna(mean_review_value,inplace=True)\n",
    "print(df['prop_review_score'].isna().sum())\n",
    "\n",
    "\n",
    "\n",
    "#prop_location_score2\n",
    "print(50*'-')\n",
    "print(\"location scores filling\")\n",
    "print(df['prop_location_score2'].head(10))\n",
    "country_q1_map = df.groupby('prop_country_id')['prop_location_score2'].quantile(0.25)\n",
    "global_q1_fallback_loc2 = df['prop_location_score2'].quantile(0.25)\n",
    "print(country_q1_map.head(10))\n",
    "print(global_q1_fallback_loc2)\n",
    "nans_before_imputation = df['prop_location_score2'].isnull().sum()\n",
    "print(f\"\\nMissing values in 'prop_location_score2' BEFORE imputation: {nans_before_imputation}\")\n",
    "\n",
    "imputation_values_for_nan_rows = df.loc[df['prop_location_score2'].isnull(), 'prop_country_id'].map(country_q1_map)\n",
    "df.loc[df['prop_location_score2'].isnull(), 'prop_location_score2'] = imputation_values_for_nan_rows\n",
    "df['prop_location_score2'].fillna(global_q1_fallback_loc2, inplace=True)\n",
    "\n",
    "nans_after_imputation = df['prop_location_score2'].isnull().sum()\n",
    "print(f\"Missing values in 'prop_location_score2' AFTER imputation: {nans_after_imputation}\")\n",
    "print(df['prop_location_score2'].head(10))\n",
    "sns.histplot(df['prop_location_score2'], bins=100, kde=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419720bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#orig_destination_distance\n",
    "#later we will use log_orig_destination_distance and drop the original column\n",
    "print(50*'-')\n",
    "print(\"location scores filling\")\n",
    "print(\"Distance to the property values filling\")\n",
    "df['log_orig_destination_distance'] = np.log1p(df['orig_destination_distance'])\n",
    "print(df['log_orig_destination_distance'].tail(50))\n",
    "median_log_distance = df['log_orig_destination_distance'].median()\n",
    "df['distance_missing'] = df['orig_destination_distance'].isna().astype(int)\n",
    "df['log_orig_destination_distance'].fillna(median_log_distance,inplace=True)\n",
    "print(50*'-')\n",
    "print(df['log_orig_destination_distance'].isna().sum())    \n",
    "# df['log_orig_destination_distance'].plot(kind='hist', bins=100, figsize=(15, 7), color='purple')\n",
    "sns.histplot(df['log_orig_destination_distance'], bins=50, kde=True)\n",
    "df = df.drop(columns=['orig_destination_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de57402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Price_usd fixing values \n",
    "zero_price_count = (df['price_usd'] == 0).sum()\n",
    "print(f\"Number of zero prices: {zero_price_count}\")\n",
    "positive_prices = df.loc[(df['price_usd'] > 0) & (df['price_usd'].notna()), 'price_usd']\n",
    "low_percentile_price = positive_prices.quantile(0.01) # 1st percentile\n",
    "print(f\"1st percentile of positive prices: {low_percentile_price:.2f}\")\n",
    "        \n",
    "# Replace 0s with this low percentile value\n",
    "df.loc[df['price_usd'] == 0, 'price_usd'] = low_percentile_price\n",
    "print(f\"Replaced {zero_price_count} zero price_usd values with {low_percentile_price:.2f}\")\n",
    "\n",
    "#Replace extreme outliers with the 99.5th percentile value\n",
    "upper_cap_limit = df['price_usd'].quantile(0.995)\n",
    "print(f\"99th percentile (upper cap limit) for price_usd: {upper_cap_limit:.2f}\")\n",
    "# Identify values above the cap\n",
    "outliers_above_cap = (df['price_usd'] > upper_cap_limit).sum()\n",
    "print(f\"Number of price_usd values above {upper_cap_limit:.2f}: {outliers_above_cap}\")\n",
    "\n",
    "if outliers_above_cap > 0:\n",
    "        # Cap the values: set any price_usd greater than upper_cap_limit to upper_cap_limit\n",
    "        df.loc[df['price_usd'] > upper_cap_limit, 'price_usd'] = upper_cap_limit\n",
    "        print(f\"Capped {outliers_above_cap} high outliers to {upper_cap_limit:.2f}\")\n",
    "else:\n",
    "        print(\"No high outliers found above the 99th percentile to cap.\")\n",
    "\n",
    "#Replace low extreme outliers with the 1st percentile value\n",
    "\n",
    "lower_cap_limit_low = df['price_usd'].quantile(0.01) \n",
    "print(f\"\\n1st percentile (lower cap limit) for price_usd: {lower_cap_limit_low:.2f}\")\n",
    "\n",
    "outliers_below_cap_low = (df['price_usd'] < lower_cap_limit_low).sum()\n",
    "print(f\"Number of price_usd values below {lower_cap_limit_low:.2f}: {outliers_below_cap_low}\")\n",
    "if outliers_below_cap_low > 0:\n",
    "        # Cap the values\n",
    "        df.loc[df['price_usd'] < lower_cap_limit_low, 'price_usd'] = lower_cap_limit_low\n",
    "        print(f\"Capped {outliers_below_cap_low} low outliers to {lower_cap_limit_low:.2f}\")\n",
    "else:\n",
    "        print(\"No low outliers found below the 1st percentile to cap.\")\n",
    "\n",
    "\n",
    "sns.histplot(df['price_usd'], bins=100, kde=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afceb750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visitor history missing values \n",
    "df['visitor_history_present'] = df['visitor_hist_adr_usd'].notna().astype(int)\n",
    "print(f\"Number of entries with visitor history (ADR): {df['visitor_history_present'].sum()}\")\n",
    "\n",
    "#Engineer the new feature\n",
    "df['price_diff'] = 0.0\n",
    "\n",
    "\n",
    "condition_history_present = df['visitor_hist_adr_usd'].notna()\n",
    "df.loc[condition_history_present, 'price_diff'] = df.loc[condition_history_present, 'visitor_hist_adr_usd'] - df.loc[condition_history_present, 'price_usd']\n",
    "\n",
    "print(df['price_diff'].describe(percentiles=[.01, .05, .25, .5, .75, .95, .99]))\n",
    "price_diff_with_history = df.loc[df['visitor_history_present'] == 1, 'price_diff']\n",
    "sns.histplot(price_diff_with_history, bins=100, kde=True)\n",
    "df = df.drop(columns=['visitor_hist_adr_usd'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a69dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starrating history missing values and feature engineering\n",
    "df['visitor_starrating_hist_present'] = df['visitor_hist_starrating'].notna().astype(int)\n",
    "print(df['visitor_starrating_hist_present'].sum())\n",
    "\n",
    "df['starrating_diff'] =0.0\n",
    "condition_star_history_present = df['visitor_hist_starrating'].notna() \n",
    "\n",
    "df.loc[condition_star_history_present, 'starrating_diff'] = \\\n",
    "    df.loc[condition_star_history_present, 'visitor_hist_starrating'] - df.loc[condition_star_history_present, 'prop_starrating']\n",
    "\n",
    "print(df['starrating_diff'].describe(percentiles=[.01, .05, .25, .5, .75, .95, .99]))   \n",
    "sns.histplot(df['starrating_diff'], bins=100, kde=True)\n",
    "df = df.drop(columns=['visitor_hist_starrating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['srch_query_affinity_score'])\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63521309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for competition and feature engineering\n",
    "comp_rate_cols = [f'comp{i}_rate' for i in range(1, 9)]\n",
    "comp_inv_cols = [f'comp{i}_inv' for i in range(1, 9)]\n",
    "df['expedia_price_competitiveness'] = 0\n",
    "\n",
    "#check for any cheaper alternative. we fill with -1 if there is at least one cheaper alternative\n",
    "is_any_comp_cheaper = (df[comp_rate_cols] == -1).any(axis=1)\n",
    "df.loc[is_any_comp_cheaper, 'expedia_price_competitiveness'] = -1\n",
    "\n",
    "\n",
    "\n",
    "#check for expedia advantage\n",
    "is_any_comp_better_deal_for_expedia = (df[comp_rate_cols] == 1).any(axis=1)\n",
    "\n",
    "#Basically here we fill with 1 if there is no cheaper alternative AND Expedia is better than at least one competitor\n",
    "condition_for_positive_competitiveness = (df['expedia_price_competitiveness'] == 0) & is_any_comp_better_deal_for_expedia\n",
    "df.loc[condition_for_positive_competitiveness, 'expedia_price_competitiveness'] = 1\n",
    "\n",
    "print(\"Engineered 'expedia_price_competitiveness'. Values:\")\n",
    "print(df['expedia_price_competitiveness'].value_counts(dropna=False))\n",
    "\n",
    "\n",
    "#Sole availability check \n",
    "df['expedia_has_sole_availability_among_known_comps'] = 0\n",
    "\n",
    "\n",
    "has_any_comp_inv_data = df[comp_inv_cols].notna().any(axis=1)\n",
    "is_any_comp_also_available = (df[comp_inv_cols] == 0).any(axis=1)\n",
    "\n",
    "# Expedia has sole availability if:\n",
    "# - There IS competitor inventory data AND\n",
    "# - NO competitor (with data) also has availability (i.e., all known competitor inv statuses are +1)\n",
    "condition_sole_availability = has_any_comp_inv_data & (~is_any_comp_also_available)\n",
    "df.loc[condition_sole_availability, 'expedia_has_sole_availability_among_known_comps'] = 1\n",
    "\n",
    "\n",
    "print(\"Engineered 'expedia_has_sole_availability_among_known_comps'. Values:\")\n",
    "print(df['expedia_has_sole_availability_among_known_comps'].value_counts(dropna=False))\n",
    "\n",
    "df['total_fee'] = df['price_usd']*df['srch_room_count']\n",
    "\n",
    "#Dropping original columns\n",
    "comp_rate_cols = [f'comp{i}_rate' for i in range(1, 9)]\n",
    "comp_inv_cols = [f'comp{i}_inv' for i in range(1, 9)]\n",
    "comp_diff_cols = [f'comp{i}_rate_percent_diff' for i in range(1, 9)]\n",
    "\n",
    "columns_to_drop = comp_rate_cols + comp_inv_cols + comp_diff_cols\n",
    "df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(df.isna().sum())\n",
    "print(50*'-')\n",
    "print(df.shape)\n",
    "print(50*'-')\n",
    "print(df.info())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4242013",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Generating Feature-Feature Correlation Matrix Heatmap ---\")\n",
    "\n",
    "\n",
    "numerical_predictor_cols = [\n",
    "    'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
    "    'prop_location_score1', 'prop_location_score2', 'prop_log_historical_price',\n",
    "    'position', 'price_usd', \n",
    "    'promotion_flag',\n",
    "    'srch_length_of_stay', 'srch_booking_window', 'srch_adults_count',\n",
    "    'srch_children_count', 'srch_room_count', 'srch_saturday_night_bool',\n",
    "    'random_bool',\n",
    "    'search_month',\n",
    "    'log_orig_destination_distance', 'distance_missing',\n",
    "    'visitor_history_present',\n",
    "    'price_diff',\n",
    "    'visitor_starrating_hist_present', \n",
    "    'starrating_diff',\n",
    "    'expedia_price_competitiveness',\n",
    "    'total_fee',\n",
    "    'expedia_has_sole_availability_among_known_comps'\n",
    "    \n",
    "]\n",
    "\n",
    "existing_numerical_predictor_cols = [col for col in numerical_predictor_cols if col in df.columns]\n",
    "\n",
    "if existing_numerical_predictor_cols:\n",
    "    correlation_matrix = df[existing_numerical_predictor_cols].corr()\n",
    "\n",
    "    plt.figure(figsize=(22, 20)) \n",
    "    sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt=\".2f\", linewidths=.5, vmin=-1, vmax=1)\n",
    "    plt.title('Correlation Matrix of Numerical & Flag Predictor Features', fontsize=16)\n",
    "    plt.xticks(fontsize=10, rotation=90) \n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numerical predictor columns identified for feature-feature correlation matrix.\")\n",
    "\n",
    "\n",
    "# Correlation Between Features and Target Values ---\n",
    "print(\"\\n--- Generating Feature-Target Correlations ---\")\n",
    "\n",
    "targets = ['click_bool', 'booking_bool']\n",
    "\n",
    "if existing_numerical_predictor_cols:\n",
    "    for target in targets:\n",
    "        if target in df.columns:\n",
    "            df_for_corr = df[existing_numerical_predictor_cols + [target]].copy()\n",
    "            target_correlations = df_for_corr.corr()[target].sort_values(ascending=False)\n",
    "\n",
    "            print(f\"\\n--- Correlation with {target} ---\")\n",
    "            print(target_correlations.drop(target, errors='ignore').dropna()) \n",
    "\n",
    "            # Visualization\n",
    "            plt.figure(figsize=(8, 12)) # Made taller for more features\n",
    "            target_correlations.drop(target, errors='ignore').dropna().plot(kind='barh', colormap='viridis')\n",
    "            plt.title(f'Feature Correlation with {target}', fontsize=14)\n",
    "            plt.xlabel('Pearson Correlation Coefficient', fontsize=12)\n",
    "            plt.grid(axis='x', linestyle='--')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Target column '{target}' not found in DataFrame.\")\n",
    "else:\n",
    "    print(\"No numerical predictor columns identified for target correlation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2986b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to .CSV\n",
    "output_dir = '../data/modified/' # As per your screenshot\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "csv_output_path = os.path.join(output_dir, 'df_imputed_improved_train.csv')\n",
    "\n",
    "try:\n",
    "    df.to_csv(csv_output_path, index=False)\n",
    "except Exception as e:\n",
    "    print(f\"Error saving DataFrame to CSV: {e}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f2531",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmt_assign2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
